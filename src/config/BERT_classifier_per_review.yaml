CUDA: '2'
causal_layer: residual # null | adversarial | residual
aspect: abstract # abstract | structure | grammar_errors
cross_validation: True
cv_explanation: False
#task: classification # classification | regression
folds: 10
lexicon_size: 50 #50 #200 #1000
on_validation_set: False #True # if True will not use test set
num_features: 50 #200 # 20
# increasing number of features -> more words per sample -> reduct the mean significance of important words that only appear once
num_samples: 15000 # 15000
BATCH_SIZE: 400 # 200
loss2_mult: 2
residual:
    epochs: 125 # 200
    batch_size: 300 #300 #500 # 30
    lr: 0.0001 #0.0004# 0.0005
    hidden_dimensions:
       - 64
       - 16
    BERT_hidden_dimensions: 
        - 300
        - 100 # 10 # 300 good performance bad conf on GRU # 120 # 500
    causal_hidden_dimensions : 
        - 30 # 150 #30 # 120 # 10  # 64
        - 16 # 50 #16  # 30 # 5
    dropout: 0.05 #0.1
    dropout2: 0.2 # 0.1
    activation: ReLU
    activation2: ReLU
not_residual:
    epochs: 320 # 220
    batch_size: 500 # 300 #500 # 30
    lr: 0.0001 #0.0001# 0.00009
    hidden_dimensions:
        - 16
        #- 64
    BERT_hidden_dimensions:
        #- 300
        #- 128
        - 64
        # - 30 # 10 # 300 good performance bad conf on GRU # 120 # 500
    causal_hidden_dimensions: 
        - 10 # 30
        - 5
    dropout:  0 # 0.1 # 0.05 # 0.05
    dropout2:  0 # 0.1 #0.2
    activation: ReLU # ReLU
    activation2: ReLU

